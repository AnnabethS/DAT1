{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataCollectionDemo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHn0lcLwXdvh"
      },
      "source": [
        "# **Data Collection Demo**\n",
        "\n",
        "This Jupyter Notebook illustrates \n",
        "\n",
        "(1) **collecting data via web scaping**: how we can use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), a Python package for parsing HTML and XML documents, to parse websites and extract the data of interest.\n",
        "\n",
        "(2) **collecting data via using a website's API** how we can use the API of MetOffice to get a three-hourly five-day forecast for a location of interest\n",
        "\n",
        "**Important Note: This demo is only provided for illustration purposes.** There may legal and/or ethical consideration of web scaping websites and you should always pay attention to the terms and conditions of the website you may want to mine.\n",
        "\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUev6lSJYwiC"
      },
      "source": [
        "### **Demo 1: Extracting The Best Selling Books From Amazon**\n",
        "\n",
        "We will use web scraping to extract the best selling book from Amazon as listed at [https://www.amazon.co.uk/Best-Sellers-Books/zgbs/books](https://www.amazon.co.uk/Best-Sellers-Books/zgbs/books)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBNUaHB2YwOD"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "pagesNum = 1\n",
        "\n",
        "def getAmazonBestSellers(pageNum):  \n",
        "  #Define the headers\n",
        "  headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "  #Define the template of the website we want to scrape\n",
        "  urlTemplate = 'https://www.amazon.co.uk/Best-Sellers-Books/zgbs/books/ref=zg_bs_pg_' + str(pageNum) + '?_encoding=UTF8&pg=' +str(pageNum)\n",
        "\n",
        "  #Request the data\n",
        "  r = requests.get(urlTemplate)\n",
        "\n",
        "  #Check the HTTP status code; see, https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
        "  status = r.status_code\n",
        "  if status != 200: #if not executed succesfully stop\n",
        "    return \n",
        "\n",
        "  #Get the content and instantiate a Beautifoul soup instance  \n",
        "  content = r.content\n",
        "  soup = BeautifulSoup(content)\n",
        "\n",
        "  #List to keep the data of Amazon Books\n",
        "  amazonBooks = []\n",
        "\n",
        "  #Now we need to find and analyse the HTML tags that hold the necessary data\n",
        "  for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):    \n",
        "    name = d.find('span', attrs={'class':'zg-text-center-align'})\n",
        "    n = name.find_all('img', alt=True)\n",
        "    author = d.find('a', attrs={'class':'a-size-small a-link-child'})\n",
        "    rating = d.find('span', attrs={'class':'a-icon-alt'})\n",
        "    usersRated = d.find('a', attrs={'class':'a-size-small a-link-normal'})\n",
        "    price = d.find('span', attrs={'class':'p13n-sc-price'})\n",
        "        \n",
        "    #List for keeping data of each book\n",
        "    book = []\n",
        "    \n",
        "    if name is not None:\n",
        "      book.append(n[0]['alt'])\n",
        "    else:\n",
        "      book.append(\"unknown-product\")\n",
        "      \n",
        "    if author is not None:\n",
        "      book.append(author.text)\n",
        "    elif author is None:\n",
        "      author = d.find('span', attrs={'class':'a-size-small a-color-base'})\n",
        "      if author is not None:\n",
        "        book.append(author.text)\n",
        "      else:    \n",
        "        book.append('0')\n",
        "\n",
        "    if rating is not None:\n",
        "      book.append(rating.text.strip(\" out of 5 stars\"))#remove the \"out of 5 stars\"\n",
        "    else:\n",
        "      book.append('-1')\n",
        "\n",
        "    if usersRated is not None:\n",
        "      book.append(usersRated.text.replace(\",\", \"\")) #remove the comma\n",
        "    else:\n",
        "      book.append('0')     \n",
        "\n",
        "    if price is not None:\n",
        "      book.append(price.text.strip(\"£\")) #remove the £ sign for further manipulation\n",
        "    else:\n",
        "      book.append('0')\n",
        "    \n",
        "    #Add each book's data into the list after converting its data into a tuple\n",
        "    amazonBooks.append(tuple(book))\n",
        "  \n",
        "  return amazonBooks"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB3Vv1TuYwIi",
        "outputId": "68af1fb9-1452-462e-910c-6af845e5b0e1"
      },
      "source": [
        "#Invoke the function and collect a list of tuples, one for each book\n",
        "amazonBooks = getAmazonBestSellers(1)  \n",
        "\n",
        "#Print the first 3 elements\n",
        "amazonBooks[:3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pinch of Nom Quick & Easy: 100 Delicious, Slimming Recipes',\n",
              "  'Kay Featherstone',\n",
              "  '4.9',\n",
              "  '11646',\n",
              "  '10.00'),\n",
              " ('The Boy, The Mole, The Fox and The Horse',\n",
              "  'Charlie Mackesy',\n",
              "  '4.9',\n",
              "  '46180',\n",
              "  '9.00'),\n",
              " ('The Thursday Murder Club: The Record-Breaking Sunday Times Number One Bestseller',\n",
              "  'Richard Osman',\n",
              "  '4.',\n",
              "  '34167',\n",
              "  '7.49')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjPm8nASYv-u",
        "outputId": "2179b48c-3390-4a70-b0c5-7a3426affc24"
      },
      "source": [
        "#Create the list of tuples into a numpy array\n",
        "import numpy as np\n",
        "amazonBooksArray = np.array(amazonBooks, dtype=[('name',\"U50\"), ('author',\"U50\"), ('score','f4'), ('reviews','i4'),('price','f4')])\n",
        "\n",
        "#Print the first 10 elements of the array\n",
        "amazonBooksArray[0:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([('Pinch of Nom Quick & Easy: 100 Delicious, Slimming', 'Kay Featherstone', 4.9,  11646, 10.  ),\n",
              "       ('The Boy, The Mole, The Fox and The Horse', 'Charlie Mackesy', 4.9,  46180,  9.  ),\n",
              "       ('The Thursday Murder Club: The Record-Breaking Sund', 'Richard Osman', 4. ,  34167,  7.49),\n",
              "       ('Pinch of Nom: 100 Slimming, Home-style Recipes', 'Kay Featherstone', 4.8,  39432,  9.99),\n",
              "       ('Pinch of Nom Everyday Light: 100 Tasty, Slimming R', 'Kay Featherstone', 4.8,  22878,  9.99),\n",
              "       ('Where the Crawdads Sing', 'Delia Owens', 4.7, 135417,  5.99),\n",
              "       ('Good Vibes, Good Life: How Self-Love Is the Key to', 'Vex King', 4.7,  12086,  7.99),\n",
              "       ('Why Men Love Bitches: From Doormat to Dreamgirl - ', 'Sherry Argov', 4. ,   8070, 11.19),\n",
              "       ('Bridgerton: The Duke and I (Bridgertons Book 1): T', 'Julia Quinn', 4.4,   7804,  6.  ),\n",
              "       ('Read Write Inc. Phonics: Home More Phonics Flashca', 'Ruth Miskin', 4.8,   2273,  5.74)],\n",
              "      dtype=[('name', '<U50'), ('author', '<U50'), ('score', '<f4'), ('reviews', '<i4'), ('price', '<f4')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKnjXZPJdd_Z",
        "outputId": "8d8c8f3f-27a5-4dfe-abe4-e45e2b6b5dd9"
      },
      "source": [
        "#Fron now on we can analyse the dataset as normally\n",
        "#For instance, let's calculate the mean, median, standard deviation price of the best selling books\n",
        "print(\"Mean price:\",   np.mean(amazonBooksArray['price']))\n",
        "print(\"Median price:\", np.median(amazonBooksArray['price']))\n",
        "print(\"Std price:\",    np.std(amazonBooksArray['price']))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean price: 7.3641996\n",
            "Median price: 6.745\n",
            "Std price: 3.6471958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTjP4tPwd4qt"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWUBnLTDd596"
      },
      "source": [
        "### **Demo 2: Extracting The Best Hotels In York From Booking.Com**\n",
        "\n",
        "We will use web scraping to extract the Hotels in York according to Booking.com as reported at [https://www.booking.com/city/gb/york.en-gb.html](https://www.booking.com/city/gb/york.en-gb.html[link text](https://))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHBT1EdVhnuy"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def getBestYorkHotels ():\n",
        "  #Define the headers\n",
        "  headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "  #Define the template of the website we want to scrape\n",
        "  urlTemplate = 'https://www.booking.com/city/gb/york.en-gb.html'\n",
        "\n",
        "  #Request the data\n",
        "  r = requests.get(urlTemplate)\n",
        "\n",
        "  #Check the HTTP status code; see, https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
        "  status = r.status_code\n",
        "  if status != 200: #if not executed succesfully stop\n",
        "    return \n",
        "\n",
        "  #Get the content and instantiate a Beautifoul soup instance  \n",
        "  content = r.content\n",
        "  soup = BeautifulSoup(content)\n",
        "\n",
        "  #List to keep the data of the best hotels \n",
        "  #To do this, we need to extract the necessary HTML tags from the website\n",
        "  #In this case, we need the name of the hotel, its rating, the number of reviews, and its price per night\n",
        "  bestHotels = []\n",
        "\n",
        "  hotels = soup.findAll('div', attrs={'class':'sr__card_main_row bui-spacer--large'})\n",
        "  for h in hotels:\n",
        "    name = h.find('span', attrs={'class': 'bui-card__title'})\n",
        "    nameS = name.text.strip()\n",
        "\n",
        "    score = h.find('div', attrs={'class': 'bui-review-score__badge'})\n",
        "    scoreS = score.text.strip()\n",
        "\n",
        "    scoreStr = h.find('div', attrs={'class': 'bui-review-score__title'})\n",
        "    scoreStrS = scoreStr.text.strip()\n",
        "\n",
        "    reviews = h.find('div', attrs={'class': 'bui-review-score__text'})\n",
        "    reviewsS = reviews.text.strip()\n",
        "    reviewsS = reviewsS.strip(\" reviews\")\n",
        "    reviewsS = reviewsS.replace(\",\", \"\")\n",
        "\n",
        "    price = h.find('div', attrs={'class': 'bui-price-display__value bui-f-color-constructive'})\n",
        "    priceS = price.text.strip()\n",
        "    priceS = priceS.strip(\"£\")\n",
        "\n",
        "    bestHotels.append((nameS, scoreS, scoreStrS, reviewsS, priceS))\n",
        "\n",
        "  return bestHotels\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC_-63t7eLNx",
        "outputId": "aa6a8a95-d00d-449b-923f-4991f26ad586"
      },
      "source": [
        "#Invoke the function and collect a list of tuples, one for each hotel\n",
        "bestYorkHotels = getBestYorkHotels()\n",
        "\n",
        "#Print the hotels' details\n",
        "bestYorkHotels"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Park Inn by Radisson York City Centre', '8.4', 'Very good', '7557', '63'),\n",
              " ('The Grand, York', '9.2', 'Superb', '6817', '139'),\n",
              " ('Hampton by Hilton York', '8.8', 'Fabulous', '5812', '64'),\n",
              " ('DoubleTree by Hilton York', '8.1', 'Very good', '3968', '81'),\n",
              " ('Novotel York Centre', '8.2', 'Very good', '5267', '61'),\n",
              " ('Hilton York', '8.1', 'Very good', '4034', '86'),\n",
              " ('ibis York Centre', '7.4', 'Good', '5724', '35'),\n",
              " ('Elmbank Hotel And Lodge - part of The Cairn Collection',\n",
              "  '8.7',\n",
              "  'Fabulous',\n",
              "  '2490',\n",
              "  '70'),\n",
              " ('Hotel Indigo York', '8.9', 'Fabulous', '3548', '88'),\n",
              " ('Principal York', '8.2', 'Very good', '3407', '119')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md9bPwlPfBvY",
        "outputId": "8b7a01e2-4d8d-4aff-f735-e86ae06111ba"
      },
      "source": [
        "#Create the list of tuples into a numpy array\n",
        "import numpy as np\n",
        "hotelsArray = np.array(bestYorkHotels, dtype=[('name',\"U50\"), ('score','f4'), ('scoreStr','U20'), ('reviews','i4'),('price','f4')])\n",
        "\n",
        "#Print the hotels \n",
        "hotelsArray"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([('Park Inn by Radisson York City Centre', 8.4, 'Very good', 7557,  63.),\n",
              "       ('The Grand, York', 9.2, 'Superb', 6817, 139.),\n",
              "       ('Hampton by Hilton York', 8.8, 'Fabulous', 5812,  64.),\n",
              "       ('DoubleTree by Hilton York', 8.1, 'Very good', 3968,  81.),\n",
              "       ('Novotel York Centre', 8.2, 'Very good', 5267,  61.),\n",
              "       ('Hilton York', 8.1, 'Very good', 4034,  86.),\n",
              "       ('ibis York Centre', 7.4, 'Good', 5724,  35.),\n",
              "       ('Elmbank Hotel And Lodge - part of The Cairn Collec', 8.7, 'Fabulous', 2490,  70.),\n",
              "       ('Hotel Indigo York', 8.9, 'Fabulous', 3548,  88.),\n",
              "       ('Principal York', 8.2, 'Very good', 3407, 119.)],\n",
              "      dtype=[('name', '<U50'), ('score', '<f4'), ('scoreStr', '<U20'), ('reviews', '<i4'), ('price', '<f4')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSHPJ4gEfRAt",
        "outputId": "c9a7099c-c4f6-4c69-d853-4474f649dbcd"
      },
      "source": [
        "#Fron now on we can analyse the dataset as normally\n",
        "#For instance, let's calculate the mean, median, standard deviation of the score of the best hotels books\n",
        "print(\"Mean price:\",   np.mean(hotelsArray['score']))\n",
        "print(\"Median price:\", np.median(hotelsArray['score']))\n",
        "print(\"Std price:\",    np.std(hotelsArray['score']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean price: 8.4\n",
            "Median price: 8.299999\n",
            "Std price: 0.48989785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIcY-lpXfZ3Q"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtOUz8YmfbVt"
      },
      "source": [
        "### **Demo 3: Extracting The Weather Forecast Using MetOffice's API**\n",
        "\n",
        "We will use the API provide by MetOffice to extract the three-hourly five-day forecast for Dunkeswell Aerodrome.\n",
        "For more information see (https://www.metoffice.gov.uk/services/data/datapoint/api-reference)[https://www.metoffice.gov.uk/services/data/datapoint/api-reference]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46rt0iwGf2J-"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "#Define the template of the website we want to scrape\n",
        "#I have download the weather forecast from 28/01/21 to 01/02/21 and saved it at\n",
        "#You can also view its contents by pasting the link below at your browser\n",
        "urlTemplate = \"https://www-users.cs.york.ac.uk/simos/DAT1/yorkWeather.json\"\n",
        "\n",
        "#Request the data\n",
        "r = requests.get(urlTemplate)\n",
        "\n",
        "#Check the HTTP status code; see, https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
        "status = r.status_code\n",
        "if status != 200: #if not executed succesfully stop\n",
        "  exit\n",
        "    \n",
        "#Create a JSON object\n",
        "#Read more about the JSON format at https://en.wikipedia.org/wiki/JSON\n",
        "yorkData = r.json()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5K23Ey7dajm",
        "outputId": "081b7627-619e-4916-d0aa-ecd0042f2950"
      },
      "source": [
        "#Print the JSON object\n",
        "yorkData"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'SiteRep': {'DV': {'Location': {'Period': [{'Rep': [{'$': '1080',\n",
              "        'D': 'S',\n",
              "        'F': '2',\n",
              "        'G': '11',\n",
              "        'H': '99',\n",
              "        'Pp': '18',\n",
              "        'S': '7',\n",
              "        'T': '5',\n",
              "        'U': '0',\n",
              "        'V': 'PO',\n",
              "        'W': '5'},\n",
              "       {'$': '1260',\n",
              "        'D': 'SE',\n",
              "        'F': '3',\n",
              "        'G': '16',\n",
              "        'H': '98',\n",
              "        'Pp': '97',\n",
              "        'S': '4',\n",
              "        'T': '5',\n",
              "        'U': '0',\n",
              "        'V': 'PO',\n",
              "        'W': '15'}],\n",
              "      'type': 'Day',\n",
              "      'value': '2021-01-28Z'},\n",
              "     {'Rep': [{'$': '0',\n",
              "        'D': 'SW',\n",
              "        'F': '6',\n",
              "        'G': '20',\n",
              "        'H': '96',\n",
              "        'Pp': '94',\n",
              "        'S': '7',\n",
              "        'T': '8',\n",
              "        'U': '0',\n",
              "        'V': 'MO',\n",
              "        'W': '15'},\n",
              "       {'$': '180',\n",
              "        'D': 'WSW',\n",
              "        'F': '5',\n",
              "        'G': '27',\n",
              "        'H': '91',\n",
              "        'Pp': '1',\n",
              "        'S': '11',\n",
              "        'T': '8',\n",
              "        'U': '0',\n",
              "        'V': 'GO',\n",
              "        'W': '2'},\n",
              "       {'$': '360',\n",
              "        'D': 'WSW',\n",
              "        'F': '3',\n",
              "        'G': '25',\n",
              "        'H': '90',\n",
              "        'Pp': '2',\n",
              "        'S': '11',\n",
              "        'T': '6',\n",
              "        'U': '0',\n",
              "        'V': 'GO',\n",
              "        'W': '0'},\n",
              "       {'$': '540',\n",
              "        'D': 'W',\n",
              "        'F': '3',\n",
              "        'G': '20',\n",
              "        'H': '93',\n",
              "        'Pp': '6',\n",
              "        'S': '9',\n",
              "        'T': '6',\n",
              "        'U': '1',\n",
              "        'V': 'GO',\n",
              "        'W': '3'},\n",
              "       {'$': '720',\n",
              "        'D': 'NW',\n",
              "        'F': '5',\n",
              "        'G': '18',\n",
              "        'H': '88',\n",
              "        'Pp': '11',\n",
              "        'S': '9',\n",
              "        'T': '7',\n",
              "        'U': '1',\n",
              "        'V': 'GO',\n",
              "        'W': '7'},\n",
              "       {'$': '900',\n",
              "        'D': 'NNW',\n",
              "        'F': '4',\n",
              "        'G': '18',\n",
              "        'H': '87',\n",
              "        'Pp': '14',\n",
              "        'S': '9',\n",
              "        'T': '7',\n",
              "        'U': '1',\n",
              "        'V': 'GO',\n",
              "        'W': '7'},\n",
              "       {'$': '1080',\n",
              "        'D': 'NNE',\n",
              "        'F': '1',\n",
              "        'G': '20',\n",
              "        'H': '91',\n",
              "        'Pp': '13',\n",
              "        'S': '11',\n",
              "        'T': '5',\n",
              "        'U': '0',\n",
              "        'V': 'GO',\n",
              "        'W': '8'},\n",
              "       {'$': '1260',\n",
              "        'D': 'NE',\n",
              "        'F': '1',\n",
              "        'G': '13',\n",
              "        'H': '89',\n",
              "        'Pp': '47',\n",
              "        'S': '7',\n",
              "        'T': '4',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '8'}],\n",
              "      'type': 'Day',\n",
              "      'value': '2021-01-29Z'},\n",
              "     {'Rep': [{'$': '0',\n",
              "        'D': 'ENE',\n",
              "        'F': '0',\n",
              "        'G': '13',\n",
              "        'H': '90',\n",
              "        'Pp': '6',\n",
              "        'S': '7',\n",
              "        'T': '3',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '180',\n",
              "        'D': 'E',\n",
              "        'F': '-1',\n",
              "        'G': '16',\n",
              "        'H': '86',\n",
              "        'Pp': '6',\n",
              "        'S': '7',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '360',\n",
              "        'D': 'ENE',\n",
              "        'F': '-1',\n",
              "        'G': '20',\n",
              "        'H': '77',\n",
              "        'Pp': '6',\n",
              "        'S': '9',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '540',\n",
              "        'D': 'ENE',\n",
              "        'F': '-1',\n",
              "        'G': '20',\n",
              "        'H': '75',\n",
              "        'Pp': '6',\n",
              "        'S': '9',\n",
              "        'T': '3',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '720',\n",
              "        'D': 'ENE',\n",
              "        'F': '0',\n",
              "        'G': '25',\n",
              "        'H': '61',\n",
              "        'Pp': '6',\n",
              "        'S': '13',\n",
              "        'T': '4',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '900',\n",
              "        'D': 'ENE',\n",
              "        'F': '1',\n",
              "        'G': '20',\n",
              "        'H': '58',\n",
              "        'Pp': '5',\n",
              "        'S': '11',\n",
              "        'T': '4',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '1080',\n",
              "        'D': 'NE',\n",
              "        'F': '-1',\n",
              "        'G': '13',\n",
              "        'H': '72',\n",
              "        'Pp': '1',\n",
              "        'S': '7',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '2'},\n",
              "       {'$': '1260',\n",
              "        'D': 'NNE',\n",
              "        'F': '-2',\n",
              "        'G': '11',\n",
              "        'H': '78',\n",
              "        'Pp': '1',\n",
              "        'S': '7',\n",
              "        'T': '1',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '0'}],\n",
              "      'type': 'Day',\n",
              "      'value': '2021-01-30Z'},\n",
              "     {'Rep': [{'$': '0',\n",
              "        'D': 'NNE',\n",
              "        'F': '-3',\n",
              "        'G': '9',\n",
              "        'H': '85',\n",
              "        'Pp': '1',\n",
              "        'S': '4',\n",
              "        'T': '0',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '2'},\n",
              "       {'$': '180',\n",
              "        'D': 'NNE',\n",
              "        'F': '-4',\n",
              "        'G': '7',\n",
              "        'H': '87',\n",
              "        'Pp': '4',\n",
              "        'S': '4',\n",
              "        'T': '-1',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '360',\n",
              "        'D': 'NNE',\n",
              "        'F': '-4',\n",
              "        'G': '7',\n",
              "        'H': '88',\n",
              "        'Pp': '2',\n",
              "        'S': '4',\n",
              "        'T': '-1',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '2'},\n",
              "       {'$': '540',\n",
              "        'D': 'SSE',\n",
              "        'F': '-2',\n",
              "        'G': '7',\n",
              "        'H': '85',\n",
              "        'Pp': '5',\n",
              "        'S': '4',\n",
              "        'T': '0',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '720',\n",
              "        'D': 'SSE',\n",
              "        'F': '1',\n",
              "        'G': '13',\n",
              "        'H': '73',\n",
              "        'Pp': '4',\n",
              "        'S': '7',\n",
              "        'T': '3',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '900',\n",
              "        'D': 'SE',\n",
              "        'F': '0',\n",
              "        'G': '16',\n",
              "        'H': '70',\n",
              "        'Pp': '5',\n",
              "        'S': '9',\n",
              "        'T': '4',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '1080',\n",
              "        'D': 'ESE',\n",
              "        'F': '-2',\n",
              "        'G': '16',\n",
              "        'H': '75',\n",
              "        'Pp': '4',\n",
              "        'S': '9',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '1260',\n",
              "        'D': 'E',\n",
              "        'F': '-2',\n",
              "        'G': '16',\n",
              "        'H': '73',\n",
              "        'Pp': '4',\n",
              "        'S': '9',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'}],\n",
              "      'type': 'Day',\n",
              "      'value': '2021-01-31Z'},\n",
              "     {'Rep': [{'$': '0',\n",
              "        'D': 'E',\n",
              "        'F': '-2',\n",
              "        'G': '13',\n",
              "        'H': '76',\n",
              "        'Pp': '4',\n",
              "        'S': '9',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '180',\n",
              "        'D': 'ENE',\n",
              "        'F': '-2',\n",
              "        'G': '13',\n",
              "        'H': '79',\n",
              "        'Pp': '4',\n",
              "        'S': '7',\n",
              "        'T': '1',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '360',\n",
              "        'D': 'ENE',\n",
              "        'F': '-3',\n",
              "        'G': '11',\n",
              "        'H': '82',\n",
              "        'Pp': '2',\n",
              "        'S': '7',\n",
              "        'T': '1',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '2'},\n",
              "       {'$': '540',\n",
              "        'D': 'ENE',\n",
              "        'F': '-2',\n",
              "        'G': '11',\n",
              "        'H': '81',\n",
              "        'Pp': '4',\n",
              "        'S': '7',\n",
              "        'T': '1',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '3'},\n",
              "       {'$': '720',\n",
              "        'D': 'E',\n",
              "        'F': '2',\n",
              "        'G': '13',\n",
              "        'H': '69',\n",
              "        'Pp': '4',\n",
              "        'S': '7',\n",
              "        'T': '5',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '3'},\n",
              "       {'$': '900',\n",
              "        'D': 'E',\n",
              "        'F': '2',\n",
              "        'G': '13',\n",
              "        'H': '67',\n",
              "        'Pp': '5',\n",
              "        'S': '7',\n",
              "        'T': '5',\n",
              "        'U': '1',\n",
              "        'V': 'VG',\n",
              "        'W': '3'},\n",
              "       {'$': '1080',\n",
              "        'D': 'E',\n",
              "        'F': '-1',\n",
              "        'G': '11',\n",
              "        'H': '85',\n",
              "        'Pp': '10',\n",
              "        'S': '7',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'VG',\n",
              "        'W': '7'},\n",
              "       {'$': '1260',\n",
              "        'D': 'ESE',\n",
              "        'F': '-1',\n",
              "        'G': '11',\n",
              "        'H': '86',\n",
              "        'Pp': '12',\n",
              "        'S': '7',\n",
              "        'T': '2',\n",
              "        'U': '0',\n",
              "        'V': 'GO',\n",
              "        'W': '7'}],\n",
              "      'type': 'Day',\n",
              "      'value': '2021-02-01Z'}],\n",
              "    'continent': 'EUROPE',\n",
              "    'country': 'ENGLAND',\n",
              "    'elevation': '11.0',\n",
              "    'i': '310169',\n",
              "    'lat': '53.9621',\n",
              "    'lon': '-1.0789',\n",
              "    'name': 'YORK'},\n",
              "   'dataDate': '2021-01-28T22:00:00Z',\n",
              "   'type': 'Forecast'},\n",
              "  'Wx': {'Param': [{'$': 'Feels Like Temperature', 'name': 'F', 'units': 'C'},\n",
              "    {'$': 'Wind Gust', 'name': 'G', 'units': 'mph'},\n",
              "    {'$': 'Screen Relative Humidity', 'name': 'H', 'units': '%'},\n",
              "    {'$': 'Temperature', 'name': 'T', 'units': 'C'},\n",
              "    {'$': 'Visibility', 'name': 'V', 'units': ''},\n",
              "    {'$': 'Wind Direction', 'name': 'D', 'units': 'compass'},\n",
              "    {'$': 'Wind Speed', 'name': 'S', 'units': 'mph'},\n",
              "    {'$': 'Max UV Index', 'name': 'U', 'units': ''},\n",
              "    {'$': 'Weather Type', 'name': 'W', 'units': ''},\n",
              "    {'$': 'Precipitation Probability', 'name': 'Pp', 'units': '%'}]}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFGIiwpGZ521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf4d638-fe71-4a5b-bb0c-d8142dc010ce"
      },
      "source": [
        "#Get the dates onbjects\n",
        "data = yorkData['SiteRep']['DV']['Location']['Period']\n",
        "\n",
        "#Get the latest date (which is 01/02/21)\n",
        "date0102 = data[len(data)-1]\n",
        "\n",
        "#Since the weather forecast is in period of three hours, \n",
        "#then we expect to have the forecast for 7 periods\n",
        "time = 0\n",
        "for period in date0102['Rep']:\n",
        "  print(\"%dh-%dh => %soC\"% (time, time+3, period['T']))\n",
        "  time += 3\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0h-3h => 2oC\n",
            "3h-6h => 1oC\n",
            "6h-9h => 1oC\n",
            "9h-12h => 1oC\n",
            "12h-15h => 5oC\n",
            "15h-18h => 5oC\n",
            "18h-21h => 2oC\n",
            "21h-24h => 2oC\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}